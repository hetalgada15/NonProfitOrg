---
title: "Writing_Assignment"
output:
  pdf_document: default
  word_document: default
date: "2023-05-02"
---

```{r}
#Installing Packages:

#install.packages("GGally")
#install.packages("caret")
#install.packages("mgcv")
#install.packages("glmnet")
#install.packages("randomForest")
#install.packages("mice")
#install.packages("rmarkdown")
#install.packages("knitr")

```


```{r}
#Import the libraries:

library(ggplot2)
library(GGally)
library(readxl) # Load readxl package
library(lubridate)
```

#Data Preparation:

```{r}
#Load the data:

df2 <- read_excel("/Users/hetal/Downloads/RedactedClientConstituent_File.xlsx")
head(df2)
```


```{r}
# Check for missing values
print(colSums(is.na(df2)))
```


```{r}
#Converting the columns for easy accessibility:

colnames(df2)[colnames(df2) == "Total Lifetime Giving"] <- "Total_Lifetime_Giving"
colnames(df2)[colnames(df2) == "Last 5 Years Giving (FY17-21)"] <- "Last_5_Years_Giving"
colnames(df2)[colnames(df2) == "Last 10 Years Giving"] <- "Last_10_Years_Giving"
colnames(df2)[colnames(df2) == "Alumni Board Member"] <- "Alumni_Board_Member"
colnames(df2)[colnames(df2) == "Last Gift Date"] <- "Last_Gift_Date"
colnames(df2)[colnames(df2) == "First Gift Date"] <- "First_Gift_Date"
colnames(df2)[colnames(df2) == "Largest Gift Date"] <- "Largest_Gift_Date"
colnames(df2)[colnames(df2) == "Personal Email End"] <- "Personal_Email_End"
colnames(df2)[colnames(df2) == "Reunions attended"] <- "Reunions_attended"
colnames(df2)[colnames(df2) == "Married to an Alum"] <- "Married_to_an_Alum"
colnames(df2)[colnames(df2) == "Last Gift Date"] <- "Last_Gift_Date"
```


```{r}
##Shape of DataFrame:
dim(df2)
```


```{r}
#Finding the datatype of variables:
sapply(df2, class)
```


```{r}
#Finding the summary of dataframe:
summary(df2)
```


```{r}
#Getting the column names:
names(df2)
```

#Feature Engineering:
```{r}
#After analyzing the data, group all the similar features in same category using encoding method:

# create a new column with grouped values for CnCnstncy_1_01_CodeLong: 
df2$grouped_CnCnstncy_1_01_CodeLong <- ifelse(df2$CnCnstncy_1_01_CodeLong %in% c("Board", "Previous Board"), "Board", 
                                  ifelse(df2$CnCnstncy_1_01_CodeLong %in% c("Current Fac/Staff", "Former Fac/Staff"), "Fac/Staff", 
                                  ifelse(df2$CnCnstncy_1_01_CodeLong %in% c("Student", "Parent", "Education Certificate"), "Education/Family", 
                                  ifelse(df2$CnCnstncy_1_01_CodeLong %in% c("Friend", "Friends / Memorial"), "Friendship/Memorial", 
                                  ifelse(df2$CnCnstncy_1_01_CodeLong %in% c("Prospective Benefactor", "Organization", "Alumni", "Business", "Foundation", "Trust / Business", "Dominican Colleges and Universities", "WAICU", "Government", "Religious Org", "Unknown - Historical"), "OtherDonors", "NA")))))

# encode the labels using factor()
# encode the labels using factor() and replace NA and 0 values with 0

df2$CnCnstncy_1_01_CodeLong_Encoded <- ifelse(is.na(df2$grouped_CnCnstncy_1_01_CodeLong) | df2$grouped_CnCnstncy_1_01_CodeLong == "NA" | df2$grouped_CnCnstncy_1_01_CodeLong == 0, 0,
                                              as.integer(factor(df2$grouped_CnCnstncy_1_01_CodeLong,
                                                                 levels = c("Education/Family", "Friendship/Memorial", "Fac/Staff", "Board", "OtherDonors"),
                                                                 labels = c(1, 2, 3, 4, 5))))
```


```{r}
#After analyzing the data, group all the similar features in same category using encoding method:

# create a new column with grouped values for CnCnstncy_1_02_CodeLong:
df2$grouped_CnCnstncy_1_02_CodeLong <- ifelse(df2$CnCnstncy_1_02_CodeLong %in% c("Board", "Previous Board", "Board of Visitors Advisory Group"), "Board", 
                                  ifelse(df2$CnCnstncy_1_02_CodeLong %in% c("Current Fac/Staff", "Former Fac/Staff"), "Fac/Staff", 
                                  ifelse(df2$CnCnstncy_1_02_CodeLong %in% c("Student", "Parent", "Education Certificate"), "Education/Family", 
                                  ifelse(df2$CnCnstncy_1_02_CodeLong %in% c("Friend", "Friends / Memorial", "Friends / Athletics", "Friends / Agency"), "Friendship/Memorial", 
                                  ifelse(df2$CnCnstncy_1_02_CodeLong %in% c("Prospective Benefactor", "Organization", "Alumni", "Business", "Foundation", "Trust", "Cutting Edge Alumni", "Religious Org", "Unknown - Historical"), "OtherDonors", "NA")))))

# encode the labels using factor()
# encode the labels using factor() and replace NA and 0 values with 0
df2$CnCnstncy_1_02_CodeLong_Encoded <- ifelse(is.na(df2$grouped_CnCnstncy_1_02_CodeLong) | df2$grouped_CnCnstncy_1_02_CodeLong == "NA" | df2$grouped_CnCnstncy_1_02_CodeLong == 0, 0,
                                              as.integer(factor(df2$grouped_CnCnstncy_1_02_CodeLong,
                                  levels = c("Education/Family", "Friendship/Memorial", "Fac/Staff", "Board", "OtherDonors"),
                                  labels = c(1, 2, 3, 4, 5))))
```


```{r}
#After analyzing the data, group all the similar features in same category using encoding method:

# create a new column with grouped values for CnCnstncy_1_03_CodeLong:
df2$grouped_CnCnstncy_1_03_CodeLong <- ifelse(df2$CnCnstncy_1_03_CodeLong %in% c("Board", "Previous Board"), "Board", 
                                  ifelse(df2$CnCnstncy_1_03_CodeLong %in% c("Current Fac/Staff", "Former Fac/Staff"), "Fac/Staff", 
                                  ifelse(df2$CnCnstncy_1_03_CodeLong %in% c("Student", "Parent", "Education Certificate"), "Education/Family", 
                                  ifelse(df2$CnCnstncy_1_03_CodeLong %in% c("Friend", "Friends / Memorial"), "Friendship/Memorial", 
                                  ifelse(df2$CnCnstncy_1_03_CodeLong %in% c("Prospective Benefactor", "Organization", "Alumni"), "OtherDonors", "NA")))))

# encode the labels using factor() and replace NA and 0 values with 0
df2$CnCnstncy_1_03_CodeLong_Encoded <- ifelse(is.na(df2$grouped_CnCnstncy_1_03_CodeLong) | df2$grouped_CnCnstncy_1_03_CodeLong == "NA" | df2$grouped_CnCnstncy_1_03_CodeLong == 0, 0,
                                  as.integer(factor(df2$grouped_CnCnstncy_1_03_CodeLong,
                                  levels = c("Education/Family", "Friendship/Memorial", "Fac/Staff", "Board", "OtherDonors"),
                                  labels = c(1, 2, 3, 4, 5))))
```


```{r}
#After analyzing the data, group all the similar features in same category using encoding method:

# Create a mapping between the original labels and new encoded labels for CnCnstncy_1_04_CodeLong:
label_mapping <- c("NA" = 0, "Former Fac/Staff" = 1, "Previous Board" = 2, "Education Certificate" = 3)

# Replace missing values with "NA" label
df2$CnCnstncy_1_04_CodeLong[is.na(df2$CnCnstncy_1_04_CodeLong)] <- "NA"

# Convert the column to a factor with the new encoding
df2$CnCnstncy_1_04_CodeLong_Encoded <- factor(df2$CnCnstncy_1_04_CodeLong, labels = label_mapping)
```


```{r}

#After analyzing the data, group all the similar features in same category using encoding method:

# create a new column with grouped values for CnBio_Marital_status:
df2$grouped_CnBio_Marital_status <- ifelse(df2$CnBio_Marital_status %in% c("Married", "Partner", "Cohabitation", "Engaged"), "Committed", 
                                           ifelse(df2$CnBio_Marital_status %in% c("Divorced", "Single", "Widowed", "Separated"), "Single", 
                                                  ifelse(df2$CnBio_Marital_status %in% c("Religious"), "Worshipper", 
                                                         ifelse(is.na(df2$CnBio_Marital_status) | df2$CnBio_Marital_status == "Unknown", "Unknowns", "NA"))))

# encode the labels using factor() and replace NA and 0 values with 0
df2$CnBio_Marital_status_Encoded <- ifelse(is.na(df2$grouped_CnBio_Marital_status) | df2$grouped_CnBio_Marital_status == "NA" | df2$grouped_CnBio_Marital_status == "Unknowns", 0,
                                            as.integer(factor(df2$grouped_CnBio_Marital_status,
                                                               levels = c("Committed", "Single", "Worshipper", "Unknowns"),
                                                               labels = c(1, 2, 3, 4))))
```

```{r}
##Label Encoding to States Column:

## First find top 5 and least 5 from total_lifetime, 5years and 10 years and seee consistent or not
# Convert the category column to a factor
df2$State <- factor(df2$State)

# Convert the factor levels to integer values using as.integer()
df2$State_encoded <- as.integer(df2$State)

# Replace null and NA values with 0 using ifelse() and is.na()
df2$State_encoded <- ifelse(is.na(df2$State_encoded), 0, df2$State_encoded)

# View the resulting data frame
df2
```


```{r}

#Replacing for all the values of alumni board member to 1 and 0 for not there:
df2$Alumni_Board_Member <- ifelse(!is.na(df2$Alumni_Board_Member) & df2$Alumni_Board_Member != "", 1, 0)
```


```{r}
# Replace "O" with 0 and "l" with 1 in CnBio_Key_Deceased column:
df2$CnBio_Deceased <- ifelse(df2$CnBio_Deceased == "No", 0, 1)

# print updated data frame
print(df2)
```
```{r}
# replace "O" with 0 and "l" with 1 in CnBio_Key_Indicator column
df2$CnBio_Key_Indicator <- ifelse(df2$CnBio_Key_Indicator == "O", 0, 1)
```


```{r}
## Any Degrees Present in Education:
df2$Any_Degree_Present <- ifelse((is.na(df2$CnRelEdu_1_01_Degree) & is.na(df2$CnRelEdu_1_02_Degree)) | 
                                 (df2$CnRelEdu_1_01_Degree %in% c("None", "Unknown")) | 
                                 (df2$CnRelEdu_1_02_Degree %in% c("None", "Unknown")), 0,
                                 ifelse(!is.na(df2$CnRelEdu_1_01_Degree) & !is.na(df2$CnRelEdu_1_02_Degree), 2,1))
```

```{r}
# Extract year and month from datetime
df2$First_Gift_Year <- year(df2$First_Gift_Date)
df2$First_Gift_Month <- month(df2$First_Gift_Date)

```

#Data Cleaning:

```{r}

# Remove the rows with 0 in column 'Total_Lifetime_Giving' which is the target variable to remove distortion in the analysis:

df2 <- df2[df2$Total_Lifetime_Giving != 0, ]

# print new dataframe
print(df2)
```


```{r}
#Dropping the irrelevant columns for the donation purpose:
library(dplyr)
df2 <- df2 %>% select(-CnSpSpBio_ID,-Personal_Email_End,-Largest_Gift_Date,-Zip,-CnSpPrBs_RecordImportID,-CnBio_Title_1,-City,-Last_Gift_Date,-Married_to_an_Alum,-CnRelEdu_1_01_Class_of)
```

```{r}
#library(dplyr)
#df2 <- df2 %>% select(-CnRelEdu_1_01_Class_of)
```


```{r}
#Remove the maximum value row from Total_Lifetime_Giving
max_row <- which.max(df2$Total_Lifetime_Giving)
df2 <- df2[-max_row, ]

```

```{r}
#Taking only numeric variables:
numeric_df <- subset(df2, select = which(sapply(df2, is.numeric)))
```


```{r}
# compute the correlation matrix between all pairs of numeric columns
print(cor(numeric_df))

cor_matrix <- cor(numeric_df)

# create a heatmap of the correlation matrix
heatmap(cor_matrix, 
        Rowv = NA, Colv = NA,     # turn off row and column dendrograms
        symm = TRUE,              # use symmetric color scale
        margins = c(10, 10))  
```
#Exploratory Data Analysis:

```{r}

##Graph for :CnCnstncy_1_01_CodeLong_Encoded:

# Group the data by CnCnstncy_1_01_CodeLong and calculate the total count
grouped_df <- df2 %>% 
  group_by(CnCnstncy_1_01_CodeLong) %>% 
  summarize(total_count = n())

# Create the pie chart
ggplot(grouped_df, aes(x = "", y = total_count, fill = CnCnstncy_1_01_CodeLong)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar(theta = "y") +
  labs(x = NULL, y = NULL, fill = "CnCnstncy_1_01_CodeLong", 
       title = "Distribution of CnCnstncy_1_01_CodeLong") +
  theme_void()

##Graph for :CnCnstncy_1_02_CodeLong_Encoded:

# Group the data by CnCnstncy_1_02_CodeLong and calculate the total count
grouped_df <- df2 %>% 
  group_by(CnCnstncy_1_02_CodeLong) %>% 
  summarize(total_count = n())

# Create the pie chart
ggplot(grouped_df, aes(x = "", y = total_count, fill = CnCnstncy_1_02_CodeLong)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar(theta = "y") +
  labs(x = NULL, y = NULL, fill = "CnCnstncy_1_02_CodeLong", 
       title = "Distribution of CnCnstncy_1_02_CodeLong") +
  theme_void()


```


```{r}
# create scatter plot
ggplot(df2, aes(x = df2$First_Gift_Year, y = df2$Total_Lifetime_Giving)) +
  geom_point() +
  scale_y_continuous(limits = c(0, 110000)) +
  labs(x = "First_Gift_Year Axis Label", y = "Total_Lifetime_Giving", title = "Scatter Plot Title")

```


```{r}
# Count the frequency of each value
freq <- table(df2$Alumni)

# Create a dataframe with the counts and percentages
df_freq <- data.frame(value = as.numeric(freq), 
                      percentage = round(as.numeric(freq) / sum(as.numeric(freq)) * 100, 1))

# Create the pie chart with percentage labels
ggplot(data = df_freq, aes(x = "", y = value, fill = factor(value))) +
  geom_bar(width = 1, stat = "identity") +
  coord_polar(theta = "y") +
  geom_text(aes(label = paste0(percentage, "%")), 
            position = position_stack(vjust = 0.5)) +
  labs(title = "Alumni Member Distribution") +
  scale_fill_manual(values = c("Pink", "Yellow"), 
                    labels = c("Non-Alumni Member", "Alumni Board Member")) +
  theme_void()
```
```{r}
# Group the data by year and calculate the total lifetime giving for each year
total_giving_by_year <- df2 %>%
  group_by(First_Gift_Year) %>%
  summarize(Total_Lifetime_Giving = sum(Total_Lifetime_Giving))

ggplot(total_giving_by_year, aes(x = First_Gift_Year, y = Total_Lifetime_Giving)) +
  geom_line(color = "purple") +
  labs(x = "First Gift Year", y = "Total Lifetime Giving", title = "First Gift Year vs Total Lifetime Giving")


```

```{r}
##Dropping the rows as the values in The First Gift Year from 1900 to 1940:
library(dplyr)

numeric_df <- numeric_df %>%
  filter(First_Gift_Year > 1940)

```

```{r}
# Group the data by year and calculate the total lifetime giving for each year
total_giving_by_month <- numeric_df %>%
  group_by(First_Gift_Month) %>%
  summarize(Total_Lifetime_Giving = sum(Total_Lifetime_Giving))

ggplot(total_giving_by_month, aes(x = First_Gift_Month, y = Total_Lifetime_Giving)) +
  geom_line() +
  labs(x = "First Gift Month", y = "Total Lifetime Giving", title = "First Gift Month vs Total Lifetime Giving")
```
```{r}
library(ggplot2)
##1
# Group the data by Year and Alumni and calculate the total lifetime giving
grouped_df <- df2 %>% 
  group_by(First_Gift_Year, Alumni) %>% 
  summarize(total_lifetime_giving = sum(Total_Lifetime_Giving))

# Create the bubble chart
ggplot(grouped_df, aes(x = First_Gift_Year ,y = total_lifetime_giving, size = total_lifetime_giving, color = Alumni)) +
  geom_point() +
  scale_size(range = c(1, 10)) +
  labs(x = "Year", y = "Total Lifetime Giving", 
       title = "Bubble chart of Total Lifetime Giving by Year and Alumni")


##2

# Group the data by Year and Any_Degree_Present  and calculate the total lifetime giving
grouped_df <- df2 %>% 
  group_by(First_Gift_Year,Any_Degree_Present ) %>% 
  summarize(total_lifetime_giving = sum(Total_Lifetime_Giving))

# Create the bubble chart
ggplot(grouped_df, aes(x = First_Gift_Year ,y = total_lifetime_giving, size = total_lifetime_giving, color = Any_Degree_Present)) +
  geom_point() +
  scale_size(range = c(1, 10)) +
  labs(x = "Year", y = "Total Lifetime Giving", 
       title = "Bubble chart of Total Lifetime Giving by Year and Alumni Board Member")

```


```{r}
##1

# create the linear graph
ggplot(df2, aes(CnCnstncy_1_01_CodeLong_Encoded, Total_Lifetime_Giving)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(x = "CnCnstncy_1_01_CodeLong_Encoded", y = "Total_Lifetime_Giving", title = "Linear Graph Title")


##2
# create the linear graph
ggplot(df2, aes(First_Gift_Year, Total_Lifetime_Giving)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(x = "First_Gift_Year", y = "Total_Lifetime_Giving", title = "Linear Graph Title")


##3
# create the linear graph
ggplot(df2, aes(Last_10_Years_Giving, Total_Lifetime_Giving)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(x = "Last_10_Years_Giving", y = "Total_Lifetime_Giving", title = "Linear Graph Title")
```


```{r}
library(dplyr) # load the dplyr package for data manipulation

# sort the data frame by Total_Lifetime_Giving in descending order, and select the top 10 states
topstates <- df2 %>%
  arrange(desc(Total_Lifetime_Giving)) %>%
  slice(1:40) %>%
  pull(State)

# create a scatter plot for the top states
ggplot(data = filter(df2, State %in% topstates),
       aes(x = State, y = Total_Lifetime_Giving)) +
  geom_point() +
  labs(x = "State", y = "Total Lifetime Giving") +
  ylim(0, 1200000) # adjust the y-axis limits to accommodate the highest value
```


```{r}
library(ggplot2)
library(dplyr)
##Topwith Total 
df_top10 <- df2 %>%
  group_by(State) %>%
  summarise(Total_Lifetime_Giving = sum(Total_Lifetime_Giving)) %>%
  filter(State != "N/A") %>%
  arrange(desc(Total_Lifetime_Giving)) %>%
  head(10)

ggplot(df_top10, aes(x = reorder(State, Total_Lifetime_Giving), y = Total_Lifetime_Giving)) +
  geom_bar(stat = "identity", fill = "blue") +
  ggtitle("Top 10 Highest States by Total Lifetime Giving") +
  xlab("State") +
  ylab("Total Lifetime Giving") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

##bottom with total
df_bottom10 <- df2 %>%
  group_by(State) %>%
  summarise(Total_Lifetime_Giving = sum(Total_Lifetime_Giving)) %>%
  filter(State != "N/A") %>%
  arrange(Total_Lifetime_Giving) %>%
  head(10)

ggplot(df_bottom10, aes(x = reorder(State, Total_Lifetime_Giving), y = Total_Lifetime_Giving)) +
  geom_bar(stat = "identity", fill = "pink") +
  ggtitle("Top 10 Lowest States by Total Lifetime Giving") +
  xlab("State") +
  ylab("Total Lifetime Giving") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

#Top with 5years


df_top10 <- df2 %>%
  group_by(State) %>%
  summarise(Last_5_Years_Giving = sum(Last_5_Years_Giving)) %>%
  filter(State != "N/A") %>%
  arrange(desc(Last_5_Years_Giving)) %>%
  head(10)

ggplot(df_top10, aes(x = reorder(State, Last_5_Years_Giving), y = Last_5_Years_Giving)) +
  geom_bar(stat = "identity", fill = "blue") +
  ggtitle("Top 10 Highest States by Last_5_Years_Giving") +
  xlab("State") +
  ylab("Last_5_Years_Giving") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

#bottom with the 5 years

df_bottom10 <- df2 %>%
  group_by(State) %>%
  summarise(Last_5_Years_Giving = sum(Last_5_Years_Giving)) %>%
  filter(State != "N/A") %>%
  arrange(Last_5_Years_Giving) %>%
  head(10)

ggplot(df_bottom10, aes(x = reorder(State, Last_5_Years_Giving), y = Last_5_Years_Giving)) +
  geom_bar(stat = "identity", fill = "pink") +
  ggtitle("Top 10 Lowest States by Last_5_Years_Giving") +
  xlab("State") +
  ylab("Last_5_Years_Giving") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))


#top with 10 years
df_top10 <- df2 %>%
  group_by(State) %>%
  summarise(Last_10_Years_Giving = sum(Last_10_Years_Giving)) %>%
  filter(State != "N/A") %>%
  arrange(desc(Last_10_Years_Giving)) %>%
  head(10)

ggplot(df_top10, aes(x = reorder(State, Last_10_Years_Giving), y = Last_10_Years_Giving)) +
  geom_bar(stat = "identity", fill = "blue") +
  ggtitle("Top 10 Highest States by Last_10_Years_Giving") +
  xlab("State") +
  ylab("Last_10_Years_Giving") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

#Bottom 10 with Last 10 years
df_bottom10 <- df2 %>%
  group_by(State) %>%
  summarise(Last_10_Years_Giving = sum(Last_10_Years_Giving)) %>%
  filter(State != "N/A") %>%
  arrange(Last_10_Years_Giving) %>%
  head(10)

ggplot(df_bottom10, aes(x = reorder(State, Last_10_Years_Giving), y = Last_10_Years_Giving)) +
  geom_bar(stat = "identity", fill = "pink") +
  ggtitle("Top 10 Lowest States by Last_10_Years_Giving") +
  xlab("State") +
  ylab("Last_10_Years_Giving") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))


```
```{r}
#1

ggplot(data=numeric_df, aes(x=Total_Lifetime_Giving)) +
  geom_histogram(binwidth=100000, fill= "orange") +
  xlim(10000, 1000000)

#2
ggplot(data=numeric_df, aes(x=Total_Lifetime_Giving)) +
  geom_histogram(binwidth=10000, fill="darkgreen") +
  xlim(10000, 260000)


#3
ggplot(data=numeric_df, aes(x=Total_Lifetime_Giving)) +
  geom_histogram(binwidth=100000, fill="darkblue") +
  xlim(100000, 7000000)
```

```{r}
df=numeric_df

dim(df)

df$log_Total_Lifetime_Giving <- log(df$Total_Lifetime_Giving)
```

```{r}
# count missing values
colSums(is.na(numeric_df))

library(dplyr)
#numeric_df <- numeric_df %>% select(-CnRelEdu_1_01_Class_of)

#numeric_df <- numeric_df %>% select(-CnSpSpBio_ID)

```



```{r}
# Build a linear regression model
model <- lm(Total_Lifetime_Giving ~ ., data = numeric_df)

# Get the fitted values and residuals
fitted <- predict(model)
residuals <- residuals(model)

# Create a data frame with the fitted values and residuals
plot_df <- data.frame(Fitted_Values = fitted, Residuals = residuals)

# Plot the residuals against the fitted values
ggplot(plot_df, aes(Fitted_Values, Residuals)) +
  geom_point() +
  geom_smooth(se = FALSE) +
  labs(x = "Fitted Values", y = "Residuals", title = "Residual Plot")

##When conducting a residual analysis, a "residuals versus fits plot" is the most frequently created plot. It is a scatter plot of residuals on the y axis and fitted values (estimated responses) on the x axis. The plot is used to detect non-linearity.

```
#Model Evaluation:

#Finding the optimal features for analysis:
```{r}
## Lasso find the optimal variables:
# Load the glmnet package
library(glmnet)

# Convert the data to matrix format
x <- as.matrix(numeric_df[, -which(names(numeric_df) == "Total_Lifetime_Giving")])
y <- numeric_df$Total_Lifetime_Giving

# Perform LASSO regularization
lasso <- glmnet(x, y, alpha = 1)

# Plot the LASSO regularization path
plot(lasso, xvar = "lambda", label = TRUE,width = 25, height = 20)

# Choose the optimal lambda value using cross-validation
cv.lasso <- cv.glmnet(x, y, alpha = 1)
lambda <- cv.lasso$lambda.min

# Extract the coefficients for the optimal lambda value
lasso.coef <- coef(lasso, s = lambda)
lasso.coef <- lasso.coef[-1, ] # Exclude the intercept term

# Identify the most important features
lasso.features <- names(numeric_df)[-which(names(numeric_df) == "Total_Lifetime_Giving")]
lasso.features <- lasso.features[which(lasso.coef != 0)]


plot(lasso, xvar = "lambda", label = TRUE, width = 25, height = 20)
```

#Analyzing with Linear Regression with Train-Test and Validating the data:

```{r}
##On Training test and validation for linear regression:
library(caret)

# Split the data into training/validation and testing sets
set.seed(123)
trainIndex <- createDataPartition(numeric_df$Total_Lifetime_Giving, p = 0.75, list = FALSE)
train_val <- numeric_df[trainIndex, ]
test <- numeric_df[-trainIndex, ]

# Split the training/validation set into a training set and a validation set

trainIndex2 <- createDataPartition(train_val$Total_Lifetime_Giving, p = 0.7, list = FALSE)
train <- train_val[trainIndex2, ]
validation <- train_val[-trainIndex2, ]

# Fit the model using the training set
model <- lm(Total_Lifetime_Giving ~ CnCnstncy_1_02_CodeLong_Encoded + CnBio_Key_Indicator+ CnCnstncy_1_03_CodeLong_Encoded+Last_10_Years_Giving+Reunions_attended+Last_5_Years_Giving+CnCnstncy_1_01_CodeLong_Encoded,
              data = train)


# Use the model to predict the testing set
predictions_test <- predict(model, newdata = test)

# Calculate the R-squared value of the model on the validation set
rsq_val <- summary(model)$r.squared
print(rsq_val)

# Calculate the R-squared value of the model on the testing set
rsq_test <- 1 - sum((test$Total_Lifetime_Giving - predictions_test)^2) / sum((test$Total_Lifetime_Giving - mean(test$Total_Lifetime_Giving))^2)
print(rsq_test)

```

#Analyzing with Ridge Regression with Train-Test and Validating the data:
```{r}

library(glmnet)

# Split Ridge the data into training, validation, and testing sets
set.seed(123)
train_index <- sample(1:nrow(numeric_df), 0.7 * nrow(numeric_df))
val_index <- sample(setdiff(1:nrow(numeric_df), train_index), 0.2 * nrow(numeric_df))
test_index <- setdiff(setdiff(1:nrow(numeric_df), train_index), val_index)
train <- numeric_df[train_index, ]
val <- numeric_df[val_index, ]
test <- numeric_df[test_index, ]

# Prepare the data for modeling
y_train <- train$Total_Lifetime_Giving
y_val <- val$Total_Lifetime_Giving
y_test <- test$Total_Lifetime_Giving
x_train <- data.matrix(train[, c('CnCnstncy_1_02_CodeLong_Encoded', 'CnCnstncy_1_03_CodeLong_Encoded','Reunions_attended','Last_5_Years_Giving','CnCnstncy_1_01_CodeLong_Encoded','CnBio_Key_Indicator')])
x_val <- data.matrix(val[, c('CnCnstncy_1_02_CodeLong_Encoded', 'CnCnstncy_1_03_CodeLong_Encoded','Reunions_attended','Last_5_Years_Giving','CnCnstncy_1_01_CodeLong_Encoded','CnBio_Key_Indicator')])
x_test <- data.matrix(test[, c('CnCnstncy_1_02_CodeLong_Encoded', 'CnCnstncy_1_03_CodeLong_Encoded','Reunions_attended','Last_5_Years_Giving','CnCnstncy_1_01_CodeLong_Encoded','CnBio_Key_Indicator')])
x_val <- data.matrix(val[, c('CnCnstncy_1_02_CodeLong_Encoded', 'CnCnstncy_1_03_CodeLong_Encoded','Reunions_attended','Last_5_Years_Giving','CnCnstncy_1_01_CodeLong_Encoded','CnBio_Key_Indicator')])

# Fit the Ridge regression model using cross-validation on the training set
cv_model <- cv.glmnet(x_train, y_train, alpha = 0, lambda = seq(0.001, 1, length = 100))

# Extract the best lambda value using the validation set
best_lambda <- cv_model$lambda.min

# Fit the Ridge regression model with the best lambda value using the training set
best_model <- glmnet(x_train, y_train, alpha = 0, lambda = best_lambda)

# Use the fitted model to make predictions on the test set
y_predicted <- predict(best_model, s = best_lambda, newx = x_test)

# Find SST and SSE
sst <- sum((y_test - mean(y_train))^2)
sse <- sum((y_predicted - y_test)^2)

# Find R-squared
rsq <- 1 - sse/sst
rsq

```

#Analyzing with Lasso Regression with Train-Test and Validating the data:
```{r}
##lasso with validation:

# Load necessary libraries
library(caret)
library(glmnet)

# Split data into training, validation, and test sets
set.seed(123)
train_index <- createDataPartition(numeric_df$Total_Lifetime_Giving, p = 0.7, list = FALSE)
train_data <- numeric_df[train_index, ]
valid_test_data <- numeric_df[-train_index, ]
valid_index <- createDataPartition(valid_test_data$Total_Lifetime_Giving, p = 0.5, list = FALSE)
valid_data <- valid_test_data[valid_index, ]
test_data <- valid_test_data[-valid_index, ]

# Define response variable
y_train <- train_data$Total_Lifetime_Giving
y_valid <- valid_data$Total_Lifetime_Giving
y_test <- test_data$Total_Lifetime_Giving

# Define matrix of predictor variables
x_train <- data.matrix(train_data[, c('CnCnstncy_1_02_CodeLong_Encoded', 'CnCnstncy_1_03_CodeLong_Encoded','Last_10_Years_Giving','Reunions_attended','Last_5_Years_Giving','CnCnstncy_1_01_CodeLong_Encoded','CnBio_Key_Indicator')])
x_valid <- data.matrix(valid_data[, c('CnCnstncy_1_02_CodeLong_Encoded', 'CnCnstncy_1_03_CodeLong_Encoded','Last_10_Years_Giving','Reunions_attended','Last_5_Years_Giving','CnCnstncy_1_01_CodeLong_Encoded','CnBio_Key_Indicator')])
x_test <- data.matrix(test_data[, c('CnCnstncy_1_02_CodeLong_Encoded', 'CnCnstncy_1_03_CodeLong_Encoded','Last_10_Years_Giving','Reunions_attended','Last_5_Years_Giving','CnCnstncy_1_01_CodeLong_Encoded','CnBio_Key_Indicator')])

# Fit Lasso regression model using cross-validation on the training set
cv_model <- cv.glmnet(x_train, y_train, alpha = 1, lambda = seq(0.001, 1, length = 100))

# Extract the best lambda value
best_lambda <- cv_model$lambda.min

# Fit Lasso regression model with best lambda value using the combined training and validation set
best_model <- glmnet(x_train, y_train, alpha = 1, lambda = best_lambda)
y_valid_predicted <- predict(best_model, s = best_lambda, newx = x_valid)


# Make predictions on test set using the fitted model
y_test_predicted <- predict(best_model, s = best_lambda, newx = x_test)

# Find SST and SSE for test set
sst_test <- sum((y_test - mean(y_test))^2)
sse_test <- sum((y_test_predicted - y_test)^2)

# Find R-Squared for test set
rsq_test <- 1 - sse_test/sst_test
rsq_test
```

#Analyzing with Decision tree with Train-Test and Validating the data:
```{r}
##validation for decision_tree
library(pROC)
library(rpart)

# Define response variable
y <- numeric_df$Total_Lifetime_Giving

# Define matrix of predictor variables
x <- data.matrix(numeric_df[, c('CnCnstncy_1_02_CodeLong_Encoded', 'CnCnstncy_1_03_CodeLong_Encoded','Reunions_attended','Last_5_Years_Giving','CnCnstncy_1_01_CodeLong_Encoded','CnBio_Key_Indicator')])

# Split the data into training, validation, and testing sets
set.seed(123)
n <- nrow(numeric_df)
train_index <- sample(n, 0.75 * n)
valid_index <- sample(setdiff(1:n, train_index), 0.2 * n)
test_index <- setdiff(setdiff(1:n, train_index), valid_index)
x_train <- x[train_index, ]
y_train <- y[train_index]
x_valid <- x[valid_index, ]
y_valid <- y[valid_index]
x_test <- x[test_index, ]
y_test <- y[test_index]

# Fit decision tree regression model on training set
model <- rpart(y_train ~ ., data = data.frame(x_train, y_train), method = "anova")

# Use fitted model to make predictions on validation set
y_predicted_valid <- predict(model, newdata = data.frame(x_valid))

# Calculate RMSE and R-squared on validation set
rmse_valid <- sqrt(mean((y_predicted_valid - y_valid)^2))
sst_valid <- sum((y_valid - mean(y_valid))^2)
sse_valid <- sum((y_predicted_valid - y_valid)^2)
rsq_valid <- 1 - sse_valid/sst_valid

# Use fitted model to make predictions on test set
y_predicted_test <- predict(model, newdata = data.frame(x_test), type = "vector")

# Calculate R-squared on test set
sst_test <- sum((y_test - mean(y_test))^2)
sse_test <- sum((y_predicted_test - y_test)^2)
rsq_test <- 1 - sse_test/sst_test

# Print the R-squared values for test sets

cat("Test set:\n")
cat(paste0("R-squared: ", rsq_test, "\n"))


```

#Analyzing with Random forest Regression with Train-Test and Validating the data:

```{r}

library(randomForest)

# Split the data into training, validation, and testing sets
set.seed(123)
train_index <- sample(nrow(numeric_df), 0.75 * nrow(numeric_df))
val_index <- sample(setdiff(1:nrow(numeric_df), train_index), 0.2 * nrow(numeric_df))
test_index <- setdiff(setdiff(1:nrow(numeric_df), train_index), val_index)
x_train <- x[train_index, ]
y_train <- y[train_index]
x_val <- x[val_index, ]
y_val <- y[val_index]
x_test <- x[test_index, ]
y_test <- y[test_index]


# Fit random forest regression model on training set
model <- randomForest(y_train ~ ., data = data.frame(x_train, y_train))

# Use fitted model to make predictions on validation set
y_predicted_val <- predict(model, newdata = data.frame(x_val))

# Calculate R-squared on validation set
sst_val <- sum((y_val - mean(y_val))^2)
sse_val <- sum((y_predicted_val - y_val)^2)
rsq_val <- 1 - sse_val/sst_val


# Use fitted model to make predictions on test set
y_predicted_test <- predict(model, newdata = data.frame(x_test))

# Calculate R-squared on test set
sst_test <- sum((y_test - mean(y_test))^2)
sse_test <- sum((y_predicted_test - y_test)^2)
rsq_test <- 1 - sse_test/sst_test

# Print the R-squared values for test set
print(paste0("Test Set R-squared: ", rsq_test))
```

#Analyzing with SVM with Train-Test and Validating the data:
```{r}
library(e1071)

# Define response variable
y <- numeric_df$Total_Lifetime_Giving

# Define matrix of predictor variables
x <- data.matrix(df2[, c('CnCnstncy_1_02_CodeLong_Encoded', 'CnCnstncy_1_03_CodeLong_Encoded','Last_10_Years_Giving','Reunions_attended','Last_5_Years_Giving','CnCnstncy_1_01_CodeLong_Encoded','CnBio_Key_Indicator')])

# Split the data into training, validation, and testing sets
set.seed(123)
train_index <- sample(nrow(numeric_df), 0.75 * nrow(numeric_df))
val_index <- sample(setdiff(1:nrow(numeric_df), train_index), 0.2 * nrow(numeric_df))
test_index <- setdiff(setdiff(1:nrow(numeric_df), train_index), val_index)
x_train <- x[train_index, ]
y_train <- y[train_index]
x_val <- x[val_index, ]
y_val <- y[val_index]
x_test <- x[test_index, ]
y_test <- y[test_index]

# Fit support vector regression model on training set with default hyperparameters
model <- svm(y_train ~ ., data = data.frame(x_train, y_train), kernel = "radial")

# Use validation set to tune hyperparameters
tuned_model <- tune.svm(y_train ~ ., data = data.frame(x_train, y_train), kernel = "radial", gamma = 10^(-6:1), cost = 10^(-1:2), tunecontrol = tune.control(cross = 2))
summary(tuned_model)
best_gamma <- tuned_model$best.parameters$gamma
best_cost <- tuned_model$best.parameters$cost

# Fit support vector regression model on training set with tuned hyperparameters
final_model <- svm(y_train ~ ., data = data.frame(x_train, y_train), kernel = "radial", gamma = best_gamma, cost = best_cost)

# Use fitted model to make predictions on test set
y_predicted <- predict(final_model, newdata = data.frame(x_test))

# Calculate R-squared on test set
sst <- sum((y_test - mean(y_test))^2)
sse <- sum((y_predicted - y_test)^2)
rsq <- 1 - sse/sst

# Print the R-squared values
print(paste0("R-squared: ", rsq))
```





```{r}
#Filter data for price between 1,000 USD and 200,000 USD
df_filtered <- subset(numeric_df, Total_Lifetime_Giving >= 200000 & Total_Lifetime_Giving <= 5000000)

#Load the ggplot2 library
library(ggplot2)

#Create a box plot of the 'price' column of the filtered DataFrame
ggplot(df_filtered, aes(x = Total_Lifetime_Giving)) +
geom_boxplot() +
ggtitle("Price Range: $200000 to $5000000") +
theme(plot.title = element_text(hjust = 0.5),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank())
```
#Create a R2 frame:

```{r}
library(dplyr)
library(ggplot2)

# create a data frame for R-squared values
rsq_df <- data.frame(Model = c("Linear Regression","Ridge Regression","Lasso Regression","Decision Tree","Random Forest","SVM"), 
                     R_Squared = c(0.1075281,0.055,0.128, 0.3581, 0.8424,0.70267))

# reorder the data frame by R-squared values in descending order
rsq_df <- rsq_df %>% 
  arrange(desc(R_Squared)) %>% 
  mutate(Model = factor(Model, levels = Model))

# create a bar plot for R-squared values with adjusted width
ggplot(rsq_df, aes(x = Model, y = R_Squared, width = 0.3)) +
  geom_bar(stat = "identity", fill = "darkblue") +
  labs(x = "Model", y = "R-Squared", title = "Comparison of R-Squared Values") +
  theme(axis.text.x = element_text(angle = 0, vjust = 0.2, hjust = 0.5))

```


